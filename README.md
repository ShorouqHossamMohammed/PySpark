
# PySpark Learning Repository

This repository contains files and notebooks showcasing my learning journey with **PySpark**.
It includes examples, exercises, and code snippets covering key concepts in distributed data processing using Apache Spark's Python API.

## Contents

* Basic RDD operations
* DataFrame creation and transformations
* Data cleaning and manipulation
* SQL queries in PySpark
* Aggregations and group operations
* Working with different file formats (CSV, JSON, Parquet)

## Requirements

* Python 3.x
* Apache Spark with PySpark installed
* Jupyter Notebook (optional, for `.ipynb` files)

## How to Run

1. Clone this repository:

   ```bash
   git clone <repo-url>
   cd <repo-folder>
   ```
2. Install dependencies:

   ```bash
   pip install pyspark
   ```
3. Open and run the files in your Python environment or Jupyter Notebook.

## Purpose

This repo serves as a reference and practice space for understanding PySpark concepts and hands-on coding.

---

